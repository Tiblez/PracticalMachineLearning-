---
title: "Practical Machine Learning Project"
author: "Tiblez"
date: "October 30, 2016"
output: html_document
---
##Introduction
This project uses data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants to investigate how well people do a particular activity. These participants perform barbell lifts correctly and incorrectly in the following 5 different ways.  
* Class A - exactly according to the specification  
* Class B - throwing the elbows to the front  
* Class C - lifting the dumbbell only halfway  
* Class D - lowering the dumbbell only halfway and   
* Class E - throwing the hips to the front  
Class A corresponds to the specified execution of the exercise, while the other 4 classes correspond to common mistakes.
Our goal is to predict the manner in which these 6 participants did the exercise. This report describes how the prediction model is built, how cross validation is used, what the expected out of sample error is, and why the choices for developing the model are done.
The developed model was also used to predict 20 different test cases.

##Data Processing and Cleaning
The data for this project is aquired from the [Weight Lifting Exercise Dataset](http://groupware.les.inf.puc-rio.br/har).  
The training data are available here: <https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv>  
The test data are available here: <https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv>  
```{r}
training<- read.csv(url("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"),
                    na.string=c("NA","","#DIV/0!"))
testing<- read.csv(url("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"),
                   na.string=c("NA","","#DIV/0!"))
```
Columns that contain missing values were removed from both the training and testing sets. Furthermore columns 1-6 were removed since they are not needed for prediction.
```{r}
training <- training[, colSums(is.na(training)) == 0]
testing <- testing[, colSums(is.na(testing)) == 0]
training<- training[,-c(1:7)]
testing<- testing[,-c(1:7)]
```

##Model Building
###Installing required packages
```{r, results='hide', message=FALSE, warning=FALSE}
library(caret)
library(rpart)
library(rattle)
library(rpart.plot)
library(e1071)
library(randomForest)
```
###Data Splitting
To compute out of sample error, the training data is splitted in to myTraining and myTesting datasets. myTraining which constitute 60% of the dataset is used in developing our models and myTesting which consttute 40% of the dataset is used for predictive model assessment.
```{r}
set.seed(4321)
inTrain<- createDataPartition(training$classe, p=.6)[[1]]
myTraining = training[inTrain,]
myTesting = training[-inTrain,]
```

###Classification Tree
To predict the outcome, I decided to start with classification tree. 
```{r}
modfit_rpart<- train(classe ~.,data=myTraining, method="rpart")
fancyRpartPlot(modfit_rpart$finalModel)
predict_rpart<- predict(modfit_rpart, myTesting)
confusionMatrix(predict_rpart, myTesting$classe)
```
From the confusion matrix, we can see that the accuracy is 0.49. This indicates that classification trees does not predict the outcome classe very well. Therefore I proceed with random forest to see if it gives a better prdiction accuracy.

###Random Forest
```{r}
modfit_rf<- randomForest(classe ~ ., data=myTraining)
predict_rf<- predict(modfit_rf, myTesting)
confusionMatrix(predict_rf, myTesting$classe)
```
With 0.99 accuracy, random forest yielded much better results in comparison to classification tree. Therefore, I decide to use random forest model to predict the 20 different test cases in the testing dataset.

###Prediction using Random Forest
```{r}
pred <- predict(modfit_rf, newdata=testing)
PredictionResults <- data.frame(
  problem_id=testing$problem_id,
  predicted=pred)
print(PredictionResults)
```